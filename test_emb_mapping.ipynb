{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 1707274\n",
      "Total number of trainable parameters: 2122186\n",
      "Total number of trainable parameters: 11181642\n"
     ]
    }
   ],
   "source": [
    "# define a simple mlp classfier for cifar 10\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(3*32*32, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*32*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# define a simple cnn classfier for cifar 10\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet18(ResNet):\n",
    "    \"\"\"Attention maps of ResNet-18.\n",
    "    \n",
    "    Overloaded ResNet model to return attention maps.\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        g0 = self.layer1(x)\n",
    "        g1 = self.layer2(g0)\n",
    "        g2 = self.layer3(g1)\n",
    "        g3 = self.layer4(g2)\n",
    "\n",
    "        x = self.avgpool(g3)\n",
    "        emb = torch.flatten(x, 1)\n",
    "        x = self.fc(emb)\n",
    "        \n",
    "        return emb, x\n",
    "    \n",
    "mlp_clf = MLP().to('cuda')\n",
    "# print the total number of trainable parameters\n",
    "print('Total number of trainable parameters:', sum(p.numel() for p in mlp_clf.parameters() if p.requires_grad))\n",
    "\n",
    "cnn_clf = CNN().to('cuda')\n",
    "# print the total number of trainable parameters\n",
    "print('Total number of trainable parameters:', sum(p.numel() for p in cnn_clf.parameters() if p.requires_grad))\n",
    "\n",
    "baseresnet18 = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT).to('cuda')\n",
    "res_clf = ResNet18(BasicBlock, [2, 2, 2, 2]).to('cuda')\n",
    "res_clf.load_state_dict(baseresnet18.state_dict(), strict=False)\n",
    "res_clf.fc = nn.Linear(512, 10).to('cuda')\n",
    "print('Total number of trainable parameters:', sum(p.numel() for p in res_clf.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cifar 10 dataset\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 0.598\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 72.29%\n",
      "[Epoch 2] loss: 0.397\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 71.76%\n",
      "[Epoch 3] loss: 0.372\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 74.47%\n",
      "[Epoch 4] loss: 0.135\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.30%\n",
      "[Epoch 5] loss: 0.050\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.30%\n",
      "[Epoch 6] loss: 0.020\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.12%\n",
      "[Epoch 7] loss: 0.011\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 78.90%\n",
      "[Epoch 8] loss: 0.009\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.10%\n",
      "[Epoch 9] loss: 0.009\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.33%\n",
      "[Epoch 10] loss: 0.013\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 78.79%\n",
      "[Epoch 11] loss: 0.013\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.49%\n",
      "[Epoch 12] loss: 0.011\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 78.77%\n",
      "[Epoch 13] loss: 0.010\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 78.52%\n",
      "[Epoch 14] loss: 0.008\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 79.19%\n",
      "[Epoch 15] loss: 0.004\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.17%\n",
      "[Epoch 16] loss: 0.002\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.31%\n",
      "[Epoch 17] loss: 0.002\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.32%\n",
      "[Epoch 18] loss: 0.001\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.47%\n",
      "[Epoch 19] loss: 0.001\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.54%\n",
      "[Epoch 20] loss: 0.001\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 79.36%\n"
     ]
    }
   ],
   "source": [
    "# define the loss function and optimizer\n",
    "def train(model):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 14], gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "            emb, outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
    "        print('Learning rate:', optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to('cuda'), labels.to('cuda')\n",
    "                _, outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "teacher_model = train(res_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple cnn classfier for cifar 10\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        emb = self.fc1(x)\n",
    "        x = self.fc2(emb)\n",
    "        return emb, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 1.958\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 37.54%\n",
      "[Epoch 2] loss: 1.626\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 40.46%\n",
      "[Epoch 3] loss: 1.562\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 43.93%\n",
      "[Epoch 4] loss: 1.401\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 48.92%\n",
      "[Epoch 5] loss: 1.361\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 49.34%\n",
      "[Epoch 6] loss: 1.343\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 50.27%\n",
      "[Epoch 7] loss: 1.328\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 51.53%\n",
      "[Epoch 8] loss: 1.317\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 50.98%\n",
      "[Epoch 9] loss: 1.309\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 51.40%\n",
      "[Epoch 10] loss: 1.298\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 52.09%\n",
      "[Epoch 11] loss: 1.292\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 52.58%\n",
      "[Epoch 12] loss: 1.285\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 52.53%\n",
      "[Epoch 13] loss: 1.280\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 52.62%\n",
      "[Epoch 14] loss: 1.275\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 52.55%\n",
      "[Epoch 15] loss: 1.241\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.53%\n",
      "[Epoch 16] loss: 1.236\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.43%\n",
      "[Epoch 17] loss: 1.235\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.89%\n",
      "[Epoch 18] loss: 1.233\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.79%\n",
      "[Epoch 19] loss: 1.232\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.77%\n",
      "[Epoch 20] loss: 1.231\n",
      "Learning rate: 0.0001\n",
      "Accuracy of the network on the 10000 test images: 53.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_clf = CNN().to('cuda')\n",
    "train(cnn_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the student model so that it can mimic the teacher model\n",
    "student_model = None\n",
    "student_model = CNN().to('cuda')\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.01)\n",
    "# setup a cosine annealing scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4, 14], gamma=0.1)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# initialize the student model weights for better convergence\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "init_weights(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 4.609\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 2] loss: 4.607\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 3] loss: 4.607\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 4] loss: 4.607\n",
      "Learning rate: 0.01\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 5] loss: 4.605\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 6] loss: 4.605\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n",
      "[Epoch 7] loss: 4.605\n",
      "Learning rate: 0.001\n",
      "Accuracy of the network on the 10000 test images: 10.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m student_model.train()\n\u001b[32m      8\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpc-share/ATSynKD/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpc-share/ATSynKD/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpc-share/ATSynKD/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpc-share/ATSynKD/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/apps/python/3.12-el8/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/apps/python/3.12-el8/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/apps/python/3.12-el8/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/apps/python/3.12-el8/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/apps/python/3.12-el8/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.01)\n",
    "# setup a cosine annealing scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4, 14], gamma=0.1)\n",
    "\n",
    "teacher_model.eval()\n",
    "for epoch in range(20):\n",
    "    student_model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        student_emb, student_outputs = student_model(inputs)\n",
    "        teacher_emb, teacher_outputs = teacher_model(inputs)\n",
    "        student_outputs = F.softmax(student_outputs, dim=1)\n",
    "        teacher_outputs = F.softmax(teacher_outputs, dim=1)\n",
    "        ce_loss_value = ce_loss(student_outputs, teacher_outputs)\n",
    "        mse_loss_value = mse_loss(student_emb, teacher_emb)\n",
    "        label_loss = ce_loss(student_outputs, labels)\n",
    "        loss = ce_loss_value + label_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
    "    print('Learning rate:', optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "\n",
    "    student_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            _, outputs = student_model(images)\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
